{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Encoder-Decoder Transformer Training on Databricks\n",
        "\n",
        "This notebook trains an **Encoder-Decoder Transformer** (original Transformer architecture) for **Seq2Seq tasks** using **PyTorch DDP** on **multiple GPUs**.\n",
        "\n",
        "## What is Encoder-Decoder?\n",
        "\n",
        "- **Encoder**: Understands source sequence (bidirectional)\n",
        "- **Decoder**: Generates target sequence (causal)\n",
        "- **Cross-Attention**: Decoder attends to encoder output\n",
        "\n",
        "## Tasks Available\n",
        "\n",
        "1. **Reversal**: Reverse sequences (\"hello\" → \"olleh\")\n",
        "2. **Copy**: Copy sequences (\"hello\" → \"hello\")\n",
        "3. **Addition**: Math problems (\"12+34\" → \"46\")\n",
        "\n",
        "## Cluster Requirements\n",
        "\n",
        "- **Runtime**: DBR 13.3 ML or higher\n",
        "- **Driver**: Multi-GPU instance (8x A10 or V100)\n",
        "- **Workers**: 0 (single-node multi-GPU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "        print(f\"\\nGPU {i}: {props.name}\")\n",
        "        print(f\"  Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "print(f\"\\nCurrent directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup & Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install einops pyyaml tensorboard tqdm --quiet\n",
        "print(\"Packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_DIR = \"/dbfs/tmp/transformer-ddp-lm\"\n",
        "\n",
        "print(f\"Project directory: {PROJECT_DIR}\")\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(f\"Changed to: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: Upload project files or git clone:\n",
        "```bash\n",
        "%sh\n",
        "cd /dbfs/tmp\n",
        "git clone https://github.com/your-username/transformer-ddp-lm.git\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Select Task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "TASK = \"reversal\"\n",
        "\n",
        "print(f\"Selected task: {TASK}\")\n",
        "print(\"\\nAvailable tasks:\")\n",
        "print(\"  - reversal: Reverse sequences (hello -> olleh)\")\n",
        "print(\"  - copy: Copy sequences (hello -> hello)\")\n",
        "print(\"  - addition: Math problems (12+34 -> 46)\")\n",
        "\n",
        "with open('configs/enc_dec_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "config['data']['task'] = TASK\n",
        "\n",
        "with open('configs/enc_dec_config.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(f\"\\nConfig updated with task: {TASK}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Train Encoder-Decoder Transformer (Multi-GPU)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "\n",
        "print(f\"Starting Encoder-Decoder Transformer training with {num_gpus} GPUs...\")\n",
        "print(f\"Task: {TASK}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "!torchrun --standalone --nproc_per_node={num_gpus} train_enc_dec_ddp.py --config configs/enc_dec_config.yaml\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training completed!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_inputs = {\n",
        "    \"reversal\": [\"hello\", \"world\", \"transformer\"],\n",
        "    \"copy\": [\"hello\", \"world\", \"transformer\"],\n",
        "    \"addition\": [\"12+34\", \"25+37\", \"100+200\"]\n",
        "}\n",
        "\n",
        "print(f\"Testing {TASK} task:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for source in test_inputs[TASK]:\n",
        "    print(f\"\\nTesting: {source}\")\n",
        "    !python inference_enc_dec.py --checkpoint checkpoints_enc_dec/best_model.pt --source {source} --max-length 30\n",
        "    print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Interactive Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from models.transformer_enc_dec import EncoderDecoderTransformer\n",
        "from models.config import TransformerConfig\n",
        "from data.seq2seq_dataset import Seq2SeqDataset\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "checkpoint_path = 'checkpoints_enc_dec/best_model.pt'\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "model_config_dict = checkpoint['config']['model']\n",
        "model_config = TransformerConfig(\n",
        "    vocab_size=model_config_dict['vocab_size'],\n",
        "    max_seq_len=model_config_dict['max_seq_len'],\n",
        "    dim=model_config_dict['dim'],\n",
        "    depth=model_config_dict['depth'],\n",
        "    heads=model_config_dict['heads'],\n",
        "    dim_head=model_config_dict['dim_head'],\n",
        "    mlp_dim=model_config_dict['mlp_dim'],\n",
        "    dropout=model_config_dict['dropout'],\n",
        "    use_rotary_emb=False,\n",
        ")\n",
        "\n",
        "model = EncoderDecoderTransformer(model_config).to(device)\n",
        "\n",
        "state_dict = checkpoint['model_state_dict']\n",
        "if list(state_dict.keys())[0].startswith('module.'):\n",
        "    state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "dataset = Seq2SeqDataset(num_samples=1, seq_len=50, task=TASK, vocab_size=256)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Task: {TASK}\")\n",
        "print(f\"Parameters: {model.num_parameters():,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate(source_text, max_length=50, temperature=0.8):\n",
        "    src = dataset.encode(source_text)\n",
        "    src = torch.cat([src, torch.tensor([dataset.eos_token_id])])\n",
        "    src = src.unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            src,\n",
        "            max_length=max_length,\n",
        "            bos_token_id=dataset.bos_token_id,\n",
        "            eos_token_id=dataset.eos_token_id,\n",
        "            temperature=temperature,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "    \n",
        "    return dataset.decode(generated[0])\n",
        "\n",
        "test_source = \"hello world\"\n",
        "result = translate(test_source)\n",
        "\n",
        "print(f\"Source: {test_source}\")\n",
        "print(f\"Target: {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "\n",
        "1. Trained an Encoder-Decoder Transformer with multi-GPU DDP\n",
        "2. Learned Seq2Seq tasks (reversal/copy/addition)\n",
        "3. Generated outputs using the trained model\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. Try different tasks: Change `TASK` variable and rerun\n",
        "2. Adjust model size in `configs/enc_dec_config.yaml`\n",
        "3. Use your own Seq2Seq dataset\n",
        "4. Implement beam search for better generation\n",
        "\n",
        "### Files Created\n",
        "\n",
        "- **Model checkpoint**: `checkpoints_enc_dec/best_model.pt`\n",
        "- **Training logs**: `logs_enc_dec/`\n",
        "- **Config**: `configs/enc_dec_config.yaml`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
